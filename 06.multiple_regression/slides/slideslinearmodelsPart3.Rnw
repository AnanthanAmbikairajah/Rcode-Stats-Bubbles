\documentclass[10pt]{beamer}%
\usetheme{Boadilla}
\usecolortheme{seahorse}

\usepackage[utf8]{inputenc}%


\usepackage[normalem]{ulem}%strikeout
 

% graphics
%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{xcolor}%for color mixing

\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}

\usepackage{tikz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% Doc info %%%%%%%%%%%%%%%%%%%
\title[\textbf{Linear models 3:}]{Multiple regressions and interactions}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

<<Plot Options, echo=FALSE, message=FALSE>>=
#load(file = ".RData")
opts_knit$set(width=60)
opts_chunk$set(comment=NA, fig.width=8, fig.height=6, out.width='0.8\\textwidth',
               out.height='0.6\\textwidth',background='#D7DDEB', size="small")


szgr <- 2
szax <- 1.3
marr <- c(4, 4, 1, 1) + 0.1
setPar<-function(){
par(las=1,mar=marr, cex=szgr, cex.lab=szax , cex.axis=szax, lwd=2 ,pch=1, las=1)
}
setPar()
@


\begin{frame}
\maketitle
\end{frame}
%%%%%%%%%%%

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{}
    \tableofcontents[currentsection,hideothersubsections,subsectionstyle=hide]% down vote\tableofcontents[currentsection,currentsubsection,hideothersubsections,sectionstyle=show/hide,subsectionstyle=show/shaded/hide]
  \end{frame}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear model, reminder}

\begin{frame}[fragile]{A simple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope}} $\times$ {\color{orange}{Predictor}} + {\color{gray}{Error}}} \\

  <<lmprinc, echo=FALSE, dev='tikz'>>=
    setPar()
    set.seed(123)
    x <- rnorm(20)
    y <- 1 + x + rnorm(20)
    plot(x, y, xlab="\\color{orange}{Predictor}", ylab="\\color{purple}{Response}")
    lm0 <- lm(y~x)
    abline(lm0, col="red", lwd=5)
    abline(h=coef(lm0)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)

    arrows(x0 = x, y0=y, y1=lm0$fitted.values, code=0, col="gray", lwd=3)
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{A multiple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope1}} $\times$ {\color{orange}{Predictor1}} + {\color{red}{Slope2}} $\times$ {\color{orange}{Predictor2}}  + {\color{gray}{Error}}} \\
  \vspace{1cm}
\textbf{In R:}
<<eval=FALSE>>=
  lm(response ~ 1 + predictor1 + predictor2, data=data)
@


\end{frame}
%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multiple regression}

\begin{frame}[fragile]{Sequential regression}

    <<echo=FALSE>>=
    set.seed(123)
    x1 <- rnorm(n = 20)
    x2 <- rnorm(n=20) + 0.6* x1
    x3 <- rnorm(n=20) - 0.5* x1
    y <- 0.5 + x2 + 0.1*x3 +rnorm(20, 0, 0.1)
    m1 <- lm(y ~ x1)
    m2 <- lm(m1$residuals ~ x2)
    m3 <- lm(m2$residuals ~ x3)
  @
  
We want to explain a response by three predictors
\only<2>{
  <<lmprinc1, echo=FALSE, dev='tikz'>>=
    setPar()
    plot(x1, y, xlab="\\color{orange}{Predictor 1}", ylab="\\color{purple}{Response}")
    abline(m1, col="red", lwd=5)
    abline(h=coef(m1)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)
    arrows(x0 = x1, y0=y, y1=m1$fitted.values, code=0, col="gray", lwd=3)
  @
}
\only<3>{
  <<lmprinc2, echo=FALSE, dev='tikz'>>=
    setPar()
      plot(x2, m1$residuals, xlab="\\color{orange}{Predictor 2}", ylab="\\color{purple}{Residuals from 1}")
    abline(m2, col="red", lwd=5)
    abline(h=coef(m2)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)
    arrows(x0 = x2, y0=m1$residuals, y1=m2$fitted.values, code=0, col="gray", lwd=3)
  @
}
\only<4>{
  <<lmprinc3, echo=FALSE, dev='tikz'>>=
    setPar()
      plot(x3, m2$residuals, xlab="\\color{orange}{Predictor 3}", ylab="\\color{purple}{Residuals from 2}")
    abline(m3, col="red", lwd=5)
    abline(h=coef(m3)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)
    arrows(x0 = x3, y0=m2$residuals, y1=m3$fitted.values, code=0, col="gray", lwd=3)
  @
}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Sequential regression}

  <<>>=
    m1 <- lm(y ~ x1)
    m2 <- lm(m1$residuals ~ x2)
    m3 <- lm(m2$residuals ~ x3)
    @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Sequential regression}

But, 
  <<>>=
    m1 <- lm(y ~ x1)
    m2 <- lm(m1$residuals ~ x2)
    m3 <- lm(m2$residuals ~ x3)

    coefficients(m1); coefficients(m2); coefficients(m3)
    @
is different from
<<>>=
    m1 <- lm(y ~ x3)
    m2 <- lm(m1$residuals ~ x2)
    m3 <- lm(m2$residuals ~ x1)

    coefficients(m1); coefficients(m2); coefficients(m3)
    @
\end{frame}
%%%%%%%%%%%
\begin{frame}[fragile]{Sequential regression}

  Also what happens with classical ANOVA (aov in R)
  
  <<>>=
    summary(aov(y ~ x1 + x2 + x3))
    summary(aov(y ~ x2 + x3 + x1))
    @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Simultaneous regression}
In contrast lm() optimizes relationships simultaneously\\
Hence order does not matter:
  <<>>=
    coefficients(lm(y ~ x1 + x2 + x3))
    coefficients(lm(y ~ x2 + x3 + x1))
  @

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Simultaneous regression}

<<>>=
    vcov(lm(y ~ x1 + x2 + x3))
  @
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Interaction}

\begin{frame}[fragile]{Warnings}

  \begin{alertblock}{Vocabulary warning!}
    \begin{itemize}[<+->]
      \item \textbf{correlation}: linear association between two variables \textit{"how well does $x$ explain $y$ ?"}
      \item \textbf{interaction}: non-additive effect of two or more variables \textit{"does the effect of $x_1$ on $y$ change as a function of $x_2$?"}. Adds a predictor (or several) to a model.
    \end{itemize}
  \end{alertblock}

\pause
  <<histinter, echo=FALSE, dev='tikz', out.height='0.6\\textheight', out.width='0.6\\textwidth'>>=
  setPar()
    a <- 2
    b <- 3
    ab <- 5
    abi <-0.2

    barplot(height = c(a,b,ab), ylab="response", names.arg = c("a", "b", "a+b"))
    barplot(height = c(a,b,abi), add = TRUE, col="red")
    legend(x="topleft", legend = c("No interaction", "Interaction"), fill = c("gray", "red"))
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Fitting an interaction}
  <<echo=FALSE>>=
    set.seed(123)
    x1 <- rnorm(100)
    x2 <- rnorm(100)
    y <- 1 + -0.4*x1 + 0.5*x2 + 0.2*x1*x2 + rnorm(100)
  @

  <<eval=FALSE>>=
    lm(y ~ 1 + x1 * x2)
    lm(y ~ 1 + x1 + x2 + x1:x2)
  @
  \pause
  <<>>=
    summary(lm(y~ 1 + x1*x2))
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Fitting an interaction}
Why the multiplication sign?
\pause
<<>>=
x1Xx2 <- x1*x2
@
\pause
<<>>=
     summary(lm(y~ 1 + x1 + x2 + x1Xx2))
@

\end{frame}
%%%%%%%%%%%


\begin{frame}[fragile]{Warnings}
  \begin{alertblock}{Modeling warning!}
    \begin{itemize}
      \item \sout{DO NOT COMPARE P-VALUES OF TWO MODELS TO TEST FOR AN INTERACTION}
    \end{itemize}
  \end{alertblock}

<<echo=FALSE>>=
    set.seed(123)
  x <- exp(rnorm(200))
  x <- x[order(x)]
  sex <- c(rep(0, 150), rep(1, 50) )
  y <- 1 + sex * 0.0 + x*0.2 + rnorm(200, 0, 0.5)


  masssex <- data.frame(mass = x, sex=sex, movement = y)
@

<<eval=FALSE, echo=FALSE>>=


  write.csv(masssex, file = "../data/masssex.csv", row.names = FALSE)

  summary(lm(movement ~ mass, data=masssex[masssex$sex==0,]))
  summary(lm(movement ~ mass, data=masssex[masssex$sex==1,]))

  summary(lm(movement ~ mass*sex, data=masssex))
@

  \begin{alertblock}{Exercise}
    \begin{enumerate}
      \item Load the data masssex.csv
      \item Fit a simple regression explaining movement by mass for each sex separately. Is the relationship different between sexes?
      \item Fit the multiple regression explaining movement by mass, sex, and mass:sex, using the full dataset. Is the relationship different between sexes?
      \item Try to understand the discreapancy by plotting the data
    \end{enumerate}
  \end{alertblock}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Warnings}
1.
<<eval=FALSE>>=
  masssex <- read.csv(file="masssex.csv")
@
\pause
2.
<<eval=FALSE>>=
  summary(lm(movement ~ mass, data=masssex[masssex$sex==0,]))
  summary(lm(movement ~ mass, data=masssex[masssex$sex==1,]))
@
\pause
3.
<<eval=FALSE>>=
  summary(lm(movement ~ mass*sex, data=masssex))
@
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Warnings}
4.

<<intersexbehav, echo=TRUE,dev='tikz', out.height='0.7\\textheight', out.width='0.7\\textwidth', echo=FALSE>>=
setPar()
     plot(masssex[masssex$sex==0,"mass"],masssex[masssex$sex==0,"movement"],
       col="blue", xlim=range(masssex$mass), ylim=range(masssex$movement),
       xlab="mass", ylab="movement")
  points(masssex[masssex$sex==1,"mass"],masssex[masssex$sex==1,"movement"], col="red")
  legend(x="topleft", col=c("blue", "red"), legend = c("Sex 0", "Sex 1"), pch=1)
@
\end{frame}
%%%%%%%%%%%
% 
\begin{frame}[fragile]{Prediction}

<<echo=FALSE, eval=FALSE>>=
  set.seed(123)
  x1 <- rnorm(1000)
  x2 <- 0.5+rnorm(1000) + 0.5*x1
  y <- 10 + 0.1*x1 + 0.2*x2 + 0.5*x1*x2 + rnorm(1000)
  
  write.csv(x = data.frame(plantsize = y, x_location=x1, y_location=x2), file = "plantsize.csv", row.names = FALSE)
  summary(lm(y ~ x1 * x2))
  summary(lm(y ~ x1+ x2))
@
 
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
      \uncover<2>{\item Create a prediction for plant size as a function of x for two values of y}
    \end{enumerate}
  \end{exampleblock}
  
    <<>>=
    plantsize <- read.csv("plantsize.csv")
    m0 <- lm(plantsize ~ x_location + y_location, data=plantsize)
  @
  
\end{frame}
%%%%%%%%%%


\begin{frame}[fragile]{Prediction}

3.1. Predict
<<>>=
    
  newdata <- data.frame(x_location = rep(seq(-3,3, length.out = 100),2),
                        y_location = c(rep(-3, 100), rep(4,100)))
  newdata$prediction <- predict(m0, newdata = newdata)
@

\end{frame}
%%%%%%%%%%

\begin{frame}[fragile]{Prediction}

3.2 Visualize 
<<predadditive, echo=TRUE,dev='tikz', out.height='0.7\\textheight', out.width='0.7\\textwidth'>>=
  setPar()
  plot(newdata$x_location[newdata$y_location==-3], newdata$prediction[newdata$y_location==-3],
       xlab="x location", ylab="plant size", type="l", ylim = range(newdata$prediction), col="blue")
  lines(newdata$x_location[newdata$y_location==4], newdata$prediction[newdata$y_location==4], col="red")
@

  
\end{frame}
%%%%%%%%%%

\begin{frame}[fragile]{Prediction with interaction}
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
     \item Create a prediction for plant size as a function of x for two values of y and plot it
     \item Fit an interaction between x and y coordinates
     \item Create a new prediction with interaction, and plot it
    \end{enumerate}
  \end{exampleblock}
\end{frame}
%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

  <<predinteractive, echo=FALSE,dev='tikz', out.height='0.7\\textheight', out.width='0.7\\textwidth'>>=
  setPar()
    m1 <- lm(plantsize ~ x_location * y_location, data=plantsize)
    newdata <- data.frame(x_location = rep(seq(-3,3, length.out = 100),2),
                        y_location = c(rep(-3, 100), rep(4,100)))
  newdata$prediction <- predict(m1, newdata = newdata)
  plot(newdata$x_location[newdata$y_location==-3], newdata$prediction[newdata$y_location==-3],
       xlab="x location", ylab="plant size", type="l", ylim = range(newdata$prediction), col="blue")
  lines(newdata$x_location[newdata$y_location==4], newdata$prediction[newdata$y_location==4], col="red")
@

\end{frame}
%%%%%%%%%%

\begin{frame}[fragile]{Prediction with interaction}
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
     \item Create a prediction for plant size as a function of x for two values of y and plot it
     \item Fit an interaction between x and y coordinates
     \item Create a new prediction with interaction, and plot it
     \item Compare estimates and p-values across models. Do you think x location has an effect or not?
    \end{enumerate}
  \end{exampleblock}
\end{frame}
%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

  <<predinteractivemat, echo=FALSE,dev='tikz', out.height='0.7\\textheight', out.width='0.7\\textwidth'>>=
  setPar()
    m1 <- lm(plantsize ~ x_location * y_location, data=plantsize)
    newdata <- data.frame(x_location = rep(seq(-3,3, length.out = 10),10),
                        y_location = rep(seq(-3,4, length.out = 10), each=10))
  newdata$prediction <- predict(m1, newdata = newdata)
  
  library(reshape2)
  matpred <- acast(newdata, x_location~y_location, value.var="prediction")
  image(t(matpred), col = topo.colors(10))

  @

\end{frame}
%%%%%%%%%%

\begin{frame}{Next times}
  \begin{itemize}
    \item April 20th Kevin on ggplot
    \item May 4th Nina on Structural Equation Modeling
    \item then, mixed models and GLM
    \item \textbf{Other requests?}
  \end{itemize}
\end{frame}
%%%%%%%%%%%

\end{document}
