\documentclass[10pt]{beamer}%
\usetheme{Boadilla}
\usecolortheme{seahorse}

\usepackage[utf8]{inputenc}%

% graphics
%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{xcolor}%for color mixing

\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}

\usepackage{tikz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% Doc info %%%%%%%%%%%%%%%%%%%
\title[\textbf{Linear models}]{Statistical inference and linear models}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

<<Plot Options, echo=FALSE, message=FALSE>>=
#load(file = ".RData")
opts_knit$set(width=60)
opts_chunk$set(comment=NA, fig.width=8, fig.height=6, out.width='0.8\\textwidth',
               out.height='0.6\\textwidth',background='#D7DDEB')


szgr <- 2
szax <- 1.3
marr <- c(4, 4, 1, 1) + 0.1
setPar<-function(){
par(las=1,mar=marr, cex=szgr, cex.lab=szax , cex.axis=szax, lwd=2 ,pch=1, las=1)
}
setPar()
@


\begin{frame}
\maketitle	
\end{frame}
%%%%%%%%%%%

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{}
    \tableofcontents[currentsection,hideothersubsections,subsectionstyle=hide]% down vote\tableofcontents[currentsection,currentsubsection,hideothersubsections,sectionstyle=show/hide,subsectionstyle=show/shaded/hide] 
  \end{frame}
} 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear models in details}

\begin{frame}[fragile]{A simple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope}} $\times$ {\color{orange}{Predictor}} + {\color{gray}{Error}}} \\
  
  <<lmprinc, echo=FALSE, dev='tikz'>>=
    setPar()
    set.seed(123)
    x <- rnorm(20)
    y <- 1 + x + rnorm(20)
    plot(x, y, xlab="\\color{orange}{Predictor}", ylab="\\color{purple}{Response}")
    lm0 <- lm(y~x)
    abline(lm0, col="red", lwd=5)
    abline(h=coef(lm0)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)
    
    arrows(x0 = x, y0=y, y1=lm0$fitted.values, code=0, col="gray", lwd=3)
  @ 
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{A simple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope}} $\times$ {\color{orange}{Predictor}} + {\color{gray}{Error}}} \\
  \vspace{1cm}
\textbf{In R:}
<<eval=FALSE>>=
  lm(response ~ 1 + predictor1 + predictor2, data=data) 
    # equivalent to
  lm(response ~ predictor1 + predictor2, data=data) 
@
\begin{itemize}
  \item Intercept can be explicit or implicit
  \item Can remove intercept with \texttt{\dots $\sim $ 0 + \dots}
  \item Error is implicit
  \item Feed the option \texttt{data=} to keep code short, reliable and flexible
  \item Order of predictors do not matter 
\end{itemize}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Interpretation}

  <<>>=
    Ans <- read.csv(file = "Anscombe.csv")
  @
  
  <<eval=FALSE>>=
    lm1 <- lm(y ~ x , data=Ans[Ans$distri==1,])
    summary(lm1)
    plot(Ans$x[Ans$distri==1], Ans$y[Ans$distri==1],
         xlim=c(0,15), ylim=c(0,12))
    abline(lm1)  
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Interpretation}

 \begin{alertblock}{lm vs. plot}
 \begin{itemize}
   \item Fit a linear model $y \sim x $ for each of the four ``distri"
   \item Plot the relationship  $ y \sim x $ for each of the four ``distri"
   \item Can we trust these models? For what? \textit{\tiny I expect more than ``it's all bullshit"}
  \end{itemize}
 \end{alertblock}

\end{frame}
%%%%%%%%%%%

\begin{frame}{General approach}

\begin{center}
  \begin{tikzpicture}
    \node (sq) at (0,-1) {\color{red}{1. Scientific question}};
    \node (mo) at (0,-2) {2. Model and Statistical question};
    \draw[->, thick] (sq)--(mo);
    \node (dac) at (6,-2) {\color{red}{3. Data collection}};
    \draw[<->, thick] (mo)--(dac);

    \node (est) at (0,-3) {4. Estimation};
        \draw[->, thick] (mo)--(est);
    \node (unc) at (0,-3.5) {4.b Uncertainty and statistical significance};
    
    \node (che) at (0,-5) {\textbf{5. Diagnostic, check assumptions, prediction}};
        \draw[->, thick] (unc)--(che);
    \draw[->, thick] (che.west) to [out=150, in=210] (mo.west);

    \node (int) at (0,-6) {\color{red}{6. Interpret and think about the biology}};
        \draw[->, thick] (che)--(int);

  \draw[rounded corners, color=blue] (-4.5,-1.5) rectangle (4,-5.5);
  \node[anchor=north west] (r) at (-4.5,-1.5) {\includegraphics[width=0.1\textwidth]{Figures/r}};
  \end{tikzpicture}
  \end{center}
\end{frame}
%%%%%%%%%%%

\begin{frame}{Linear model basic assumptions}
Not necessarily wrong, but typical interpretation assumes:
 \begin{block}{}
     \begin{itemize}[<+->]
      \item Linear combination of parameters (including transformation, polynoms, interactions\dots)\\ \textit{Risk: biologically meaningless}
      \item Predictor not perfectly correlated \\ \textit{Risk: Model won't run, unstable convergence, or huge SE}
       \item {\color{red!20!black}{Little error in predictors}}\\ \textit{Risk: bias estimates (underestimate with Gaussian error)}
       \item {\color{red!50!black}{Gaussian error distribution}}\\ \textit{Risk: Poor predictions}
       \item {\color{red!70!black}{Homoscedasticity (constant error variance)}}\\ \textit{Risk: Over-optimistic uncertainty, unreliable predictions}
       \item {\color{red!99!black}{Independence of error}}\\ \textit{Risk: Bias and over-optimistic uncertainty}
     \end{itemize}
 \end{block}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Diagnostic: summary and plot}
  <<>>=
   lm1 <- lm(y ~ x , data=Ans[Ans$distri==1,])
   lm2 <- lm(y ~ x , data=Ans[Ans$distri==2,])
  @
  
  
  <<eval=FALSE>>=
   summary(lm1) 
   par(mfrow=c(2,2)) 
   plot(lm1)
  @
  
  <<eval=FALSE>>=
    summary(lm2) 
   plot(lm2)
    par(mfrow=c(1,1))
  @

\end{frame}

\begin{frame}[fragile]{Diagnostic: prediction}
  <<>>=
  pred2 <- predict(lm2, se.fit = TRUE, interval = "confidence")
  pred2 <- cbind(Ans[Ans$distri==2,], pred2)
  @

\pause
  <<pred2, dev='tikz', echo=FALSE>>=
  setPar()
  plot(pred2$x, pred2$y, ylim=c(0,12), col='red', pch=16, xlab="x", ylab="y")
  lines(pred2$x, pred2$fit.fit)
  arrows(x0=pred2$x, y0=pred2$fit.lwr, y1=pred2$fit.upr,
         code=3, angle=90)
  legend(x = "bottomright", legend = c("Data", "95\\% Prediction"), col = c("red", "black"), lty = c(NA,1),
         pch=c(16,NA))
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Practice lm() with parasites}

<<echo=FALSE, eval=FALSE>>=
  set.seed(123)
  ns <- 135
  x2 <- sample(x = 1:3, size = ns, replace = TRUE)
  x1 <- rnorm(ns, 0, 1) + c(-1,0,1)[x2]
  x3 <- rnorm(ns, 5, 0.1)#no effect
  x4 <- sample(x=0:1, size=ns, replace=TRUE)#unobserved
  y <- 2 + 0.3*x1 + 0.5*(x2/2)+ x4 + rnorm(ns, sd = 0.7)
  lamb <- exp(y)
  obs <- abs(sapply(X = lamb, FUN = function(x) {rpois(n = 1, lambda = x)}) + rnorm(ns, sd=0.5))

para <- data.frame(Parasite_Mass = obs, Individual_Size = x1 +6, Location = c("A","B","C")[x2], Fur_Darkness = x3)

plot(para$Parasite_Mass, x=para$Individual_Size)
summary(glm(Parasite_Mass ~ Individual_Size + as.factor(Location) + Fur_Darkness, data=para, family="quasipoisson"))

summary(lm(Parasite_Mass ~ Individual_Size + as.factor(Location) + Fur_Darkness, data=para))
hist(resid(lm(Parasite_Mass ~ Individual_Size + as.factor(Location) + Fur_Darkness, data=para)))
write.csv(x = para, file = "Para.csv", row.names = FALSE)
@
  
  \begin{alertblock}{What explains variation in parasitic load?}
  You collected ecto-parasites on some furry large mammals at three locations. Parasites break easily when we collect them and are impossible to count, so we decide to measure parasitic load as their mass. \textbf{Why do some mammals have larger parasitic load?} \pause
    \begin{itemize}
      \item Load the \texttt{Para.csv} data (don't forget: str(), summary(), plot()\dots)
      \item Model \verb+Parasite_Mass+ using \texttt{lm()}
      \item Find what variables predict \verb+Parasite_Mass+
      \item How good are your models? Assumptions? Prediction?
      \item What biological interpretation can you imagine?
      \end{itemize}
  \end{alertblock}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bonus fun}
\begin{frame}{Extra exercises}

<<echo=FALSE, eval=FALSE>>=
set.seed(123)
ns <- 35
x1 <- runif(n = ns, min = 0,max = 1)
x2 <- 1-x1 + rnorm(ns, 0, 0.001)
x3 <- x2/2

y <- x1 + rnorm(ns, sd = 0.7)

summary(lm(y ~ x1 + x2))
summary(lm(y ~ x2 + x3))

Cdata <- data.frame(y = y, x1=x1, x2=x2, x3 = x3)
write.csv(Cdata, file = "Cdata.csv", row.names = FALSE)
@

\begin{alertblock}{General R coding}
  \begin{enumerate}
    \item What is the fastest way to get row averages in a data-frame?
    \item Create a function called colVars, like colMeans but for variance
    \item Create nice plots to visualize iris data (ideally journal-quality)
  \end{enumerate}
\end{alertblock}

\begin{alertblock}{Linear models}
  \begin{enumerate}
    \item Load Cdata.csv, fit models of y predited by x1 and x2, or x2 and x3. Something is weird, what is going on? What to do?
    \item For model that can be fitted with t.test, aov, and lm, is one of the function faster?
    \item Write your own code to obtain a prediction from a lm (that is, a simpler version of the predict function), with confidence interval. (extra toughness: do it using the matrix formulation of the analytical solution to a linear model)
  \end{enumerate}
\end{alertblock}
\end{frame}
%%%%%%%%%%%


\section{Feedback wanted!}

\begin{frame}{What do you want to learn about?}

\begin{alertblock}{Topics}
  \begin{itemize}
    \item 
  \end{itemize}
\end{alertblock}

\pause

\begin{alertblock}{Do you like it? What can we improve?}
  \begin{itemize}
    \item Is it too fast
  \end{itemize}
\end{alertblock}

\end{frame}
%%%%%%%%%%%


\end{document}
